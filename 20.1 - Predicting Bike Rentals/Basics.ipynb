{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Bike Rentals\n",
    "\n",
    "Machine Learning technique used in this project: Linear Regression, Decision Trees, Random Forests\n",
    "\n",
    "## Introduction\n",
    "Bike Rental companies are getting more and more popular in many cities around the world. This is especially true in many American metro cities. These companies have sharing stations set up throughout each respective city where riders can rent bikes by the hour or day, and return them conveniently to any sharing station in the city. \n",
    "\n",
    "We'll be focusing on Washington DC in this project, and using data collected from its bike rentals from 2011-2013. The data is compiled into a csv (17380 rows) by USC and can be found here: http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset.\n",
    "\n",
    "Here are the columns that it contains:\n",
    "* instant - A unique sequential ID number for each row\n",
    "* dteday - The date of the rentals\n",
    "* season - The season in which the rentals occurred\n",
    "* yr - The year the rentals occurred\n",
    "* mnth - The month the rentals occurred\n",
    "* hr - The hour the rentals occurred\n",
    "* holiday - Whether or not the day was a holiday\n",
    "* weekday - The day of the week (as a number, 0 to 7)\n",
    "* workingday - Whether or not the day was a working day\n",
    "* weathersit - The weather (as a categorical variable)\n",
    "* temp - The temperature, on a 0-1 scale\n",
    "* atemp - The adjusted temperature\n",
    "* hum - The humidity, on a 0-1 scale\n",
    "* windspeed - The wind speed, on a 0-1 scale\n",
    "* casual - The number of casual riders (people who hadn't previously signed up with the bike sharing program)\n",
    "* registered - The number of registered riders (people who had already signed up)\n",
    "* cnt - The total number of bike rentals (casual + registered)\n",
    "\n",
    "The goal of this project will be to try to predict the number of bikes people rent in any given hour. We'll be trying to predict the 'cnt' column in this case, using all of the other columns (except 'casual' and 'registered', as they do not look very useful). \n",
    "\n",
    "To accomplish this, we will apply a few different ML models to the data and see their performance, with the ultimate goal of applying a random forests ML model by the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Exploration\n",
    "First, let's get our dataset into a readable format and do some basic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get necessary modules\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.46308763450142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>17375</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>17376</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>17377</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>17378</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>17379</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "17374    17375  2012-12-31       1   1    12  19        0        1   \n",
       "17375    17376  2012-12-31       1   1    12  20        0        1   \n",
       "17376    17377  2012-12-31       1   1    12  21        0        1   \n",
       "17377    17378  2012-12-31       1   1    12  22        0        1   \n",
       "17378    17379  2012-12-31       1   1    12  23        0        1   \n",
       "\n",
       "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
       "17374           1           2  0.26  0.2576  0.60     0.1642      11   \n",
       "17375           1           2  0.26  0.2576  0.60     0.1642       8   \n",
       "17376           1           1  0.26  0.2576  0.60     0.1642       7   \n",
       "17377           1           1  0.26  0.2727  0.56     0.1343      13   \n",
       "17378           1           1  0.26  0.2727  0.65     0.1343      12   \n",
       "\n",
       "       registered  cnt  \n",
       "17374         108  119  \n",
       "17375          81   89  \n",
       "17376          83   90  \n",
       "17377          48   61  \n",
       "17378          37   49  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get our main df\n",
    "bike_rentals = pd.read_csv(\"bike_rental_hour.csv\")\n",
    "\n",
    "# get the average rentals per day\n",
    "ave = bike_rentals['cnt'].mean()\n",
    "print(ave)\n",
    "\n",
    "# look at last few rows\n",
    "bike_rentals.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd6380be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a histogram of distribution of rentals\n",
    "plt.hist(bike_rentals['cnt'])\n",
    "plt.title(\"Distribution of Bike Rentals Per Hour\")\n",
    "plt.xlabel(\"# of Rentals\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0.278379\n",
       "season        0.178056\n",
       "yr            0.250495\n",
       "mnth          0.120638\n",
       "hr            0.394071\n",
       "holiday      -0.030927\n",
       "weekday       0.026900\n",
       "workingday    0.030284\n",
       "weathersit   -0.142426\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hum          -0.322911\n",
       "windspeed     0.093234\n",
       "casual        0.694564\n",
       "registered    0.972151\n",
       "cnt           1.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see some correlations to the total rentals\n",
    "bike_rentals.corr('pearson')[\"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a basic normal curve in terms of rental distribution, which is good and expected. We also saw some basic interesting correlations to the total rentals that are worth keeping in mind. \n",
    "\n",
    "This also helps validate the data a little bit, due to us expecting a bell curve as well as categories like outside temp having a little correlation shown, whereas categories like the day being  holiday should not really have a correlation to rentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Features\n",
    "Before applying any ML model techniques, enhancing feautures can be a good idea. This introduces \"new\" information in ways that can make the accuracy of models become more efficient. \n",
    "\n",
    "For example, the 'hr' column of the dataset contains the values 1-24, corresponding to a 24 hour clock. We can relabel these values into morning, afternoon, evening, and night labels accordingly. \n",
    "\n",
    "A machine will treat these values differently, and while it may be able to categorize the different hours into labels eventually, we probably know that 4pm correlates more to 1pm than it does 7pm already, so we can just do this ourselves. It takes a bit of intuition here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create function to assign hour labels\n",
    "def assign_label(hour):\n",
    "    if hour in range(6,12):\n",
    "        return 1\n",
    "    elif hour in range(12,18):\n",
    "        return 2\n",
    "    elif hour in range(18,24):\n",
    "        return 3\n",
    "    elif hour in range(0,6):\n",
    "        return 4\n",
    "    # account for misvalues\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [instant, dteday, season, yr, mnth, hr, holiday, weekday, workingday, weathersit, temp, atemp, hum, windspeed, casual, registered, cnt, time_label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# apply function to the hours\n",
    "bike_rentals[\"time_label\"] = bike_rentals[\"hr\"].apply(lambda x: assign_label(x))\n",
    "\n",
    "# confirm there were no faults\n",
    "print(bike_rentals[bike_rentals[\"time_label\"] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_label</th>\n",
       "      <th>hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_label  hr\n",
       "0           4   0\n",
       "1           4   1\n",
       "2           4   2\n",
       "3           4   3\n",
       "4           4   4\n",
       "5           4   5\n",
       "6           1   6\n",
       "7           1   7\n",
       "8           1   8\n",
       "9           1   9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the new column values\n",
    "bike_rentals[['time_label', 'hr']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that under our belt, we can move on to splitting the dataset up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Set Splitting\n",
    "Again, before we can apply any ML algorithms, we must have some train data and some test data to apply them too. Doing this right is extremely vital to the validation and accuracy testing process. \n",
    "\n",
    "If we don't split right, we can get an ususually low error rate that may not be the true error rate due to overfitting.\n",
    "\n",
    "Also, we will want to choose a metric for evaluating here right now. It's all subjective (with a little bit of objectiveness), so again it is all intuition. For this project, mean squared error makes the most sense to evaluate our error. MSE works on continuous numeric data, which fits our data quite well.\n",
    "\n",
    "Let's start by splitting train/test in a 80-20 relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13903\n",
      "3476\n"
     ]
    }
   ],
   "source": [
    "# get the 80% index of df\n",
    "cutoff = int(bike_rentals.shape[0] * 0.8)\n",
    "\n",
    "# set 80% of rows to train using sampling\n",
    "# random state = 1 is set for documentation purposes - remove parameter in real life\n",
    "train = bike_rentals.sample(n=cutoff, random_state=1)\n",
    "\n",
    "# set the rest of the rows to test set\n",
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]\n",
    "\n",
    "#  confirm size of each\n",
    "print(train.shape[0])\n",
    "print(test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have everything set to start using some algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Linear Regression\n",
    "Using linear regression seems to be a good start as many of our features seem to be highly correlated with our target 'cnt' column.\n",
    "\n",
    "Linear regression works best when predictors are linearly correlated to the target - aka they do not change meaning when we combine them with each other. This method is good error-wise as well because it is fairly resistant to overfitting. \n",
    "\n",
    "However, this comes with being prone to underfitting (or not building a powerful enough model). This means although linear regression is quick and efficient, sometimes it may not be the most accurate option. It is something we'll have to look out for. \n",
    "\n",
    "As mentioned before, we'll ignore the 'casual' and 'registered' columns, because these columns can be used to directly derive 'cnt'. There's no use in predicting there because we would just add them together!\n",
    "\n",
    "We're also going to choose to remove the instant, dteday, and holiday columns (subjective choices) from prediction. The first because a unique ID can't predict anything, the second because the date is aleady captured in other columns, and the third because holiday dips or surges will also be captured in the other time columns as well as the 'workingday' column, and we already saw before that this column was not very correlated with 'cnt' to begin with.\n",
    "\n",
    "Hopefully these changes will make the model more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  17070.031628725843 \n",
      "RMSE:  130.65233112625984\n"
     ]
    }
   ],
   "source": [
    "# get list of columns\n",
    "features = list(bike_rentals.columns)\n",
    "\n",
    "# remove what we don't want\n",
    "features.remove(\"cnt\")\n",
    "features.remove(\"casual\")\n",
    "features.remove(\"registered\")\n",
    "features.remove(\"dteday\")\n",
    "features.remove(\"instant\")\n",
    "features.remove(\"holiday\")\n",
    "\n",
    "# get linear regression tools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# generate linear regression instance\n",
    "lr = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "lr.fit(train[features], train[['cnt']])\n",
    "\n",
    "# make predictions on test\n",
    "predictions = lr.predict(test[features])\n",
    "\n",
    "# calculate error and root\n",
    "mse = mean_squared_error(test[['cnt']], predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# see the MSE and RMSE\n",
    "print(\"MSE: \", mse, \"\\nRMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is very high here (RMSE is over half what the average rentals per day looks like!), which may be due to the fact that the data has a few extremely high rental counts, but otherwise mostly low counts. Larger errors are penalized more with MSE, which leads to a higher total error.\n",
    "\n",
    "We could continue to re-iterate our process and work on this error using linear regression, but look to the last project (predicting stock prices) for that. For now, we have our basic idea of a linear regression model and its limitations, so let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Decision Trees\n",
    "Let's switch it up and use some decision trees now. The good news is the process is more or less the same as linear regression (Python-wise of course; the algorithms are NOT the same!). We can compare the error rate we get here to the RMSE and MSE from linear regression to determine which algorithm is better!\n",
    "\n",
    "Decision trees tend to be a little more complex than linaer regression, which means that athough they do tend to be a little more accurate, they can take more time as well. This also means they are prone to overfitting data, particularly when we don't tweak parameters like maximum depth and minimum number of samples per leaf. \n",
    "\n",
    "Lastly, decision trees are also prone to instability - small changes in the input can result in a very different model. More accuracy comes with a price! We will have to watch out for all of these things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3504.6168009205985 \n",
      "RMSE:  59.19980406150513\n"
     ]
    }
   ],
   "source": [
    "# get decision tree tools\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# generate decision tree instance - no parameters at first\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# train the model\n",
    "dt.fit(train[features], train[['cnt']])\n",
    "\n",
    "# make predictions on test\n",
    "predictions = dt.predict(test[features])\n",
    "\n",
    "# calculate error and root\n",
    "mse2 = mean_squared_error(test[['cnt']], predictions)\n",
    "rmse2 = np.sqrt(mse2)\n",
    "\n",
    "# see the MSE and RMSE\n",
    "print(\"MSE: \", mse2, \"\\nRMSE: \", rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already got a significant decrease in our error! Like we mentioned before though, it is best to hard-code the parameters of our tree class to both prevent overfitting and also to possibly reduce error if there is no overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3032.7946133413857 \n",
      "RMSE:  55.07081453312077\n"
     ]
    }
   ],
   "source": [
    "# generate new decision tree instance\n",
    "dt2 = DecisionTreeRegressor(max_depth=15, min_samples_leaf=5)\n",
    "\n",
    "# train the model\n",
    "dt2.fit(train[features], train[['cnt']])\n",
    "\n",
    "# make predictions on test\n",
    "predictions = dt2.predict(test[features])\n",
    "\n",
    "# calculate error and root\n",
    "mse3 = mean_squared_error(test[['cnt']], predictions)\n",
    "rmse3 = np.sqrt(mse3)\n",
    "\n",
    "# see the MSE and RMSE\n",
    "print(\"MSE: \", mse3, \"\\nRMSE: \", rmse3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are chosen arbitrarily and subjectively for the parameters, and playing around with them will prove to work best (there seems to be a lot of subjectiveness in ML - but that's the beauty of it! It is both a science and an art, and knowing your domain in experience can take you far). \n",
    "\n",
    "All in all, it turns out that by taking the nonlinear predictors into account (something linear regression couldn't do - or at least is not as good at doing), the decision tree regressor appears to have much higher accuracy than linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Random Forests\n",
    "Finally, we can now apply the random forest algorithm to the dataset, which improves upon the decision tree algorithm.\n",
    "\n",
    "Random forests tend to be much more accurate because of the way they are structured - they keep the same complexity of decision trees to have more accurate predictions, but also tend to overfit much less than decision trees because of the multiple \"trees\" involved (aka the name forest). \n",
    "\n",
    "Note: Being \"much less\" prone to overfitting does not mean rid of overfitting. They can still overfit, and sometimes because we think the likelihood is so small this makes it more dangerous because we are not accounting for it. It is important to thus keep the tuning of parameters in mind again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  2200.9612370828536 \n",
      "RMSE:  46.914403300935774\n"
     ]
    }
   ],
   "source": [
    "# get random forest tools\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# generate random forest instance - no parameters at first\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# train the model - we use ravel (converts to 1d array in np to avoid warnings)\n",
    "rf.fit(train[features], np.ravel(train[['cnt']]))\n",
    "\n",
    "# make predictions on test\n",
    "predictions = rf.predict(test[features])\n",
    "\n",
    "# calculate error and root\n",
    "mse4 = mean_squared_error(test[['cnt']], predictions)\n",
    "rmse4 = np.sqrt(mse4)\n",
    "\n",
    "# see the MSE and RMSE\n",
    "print(\"MSE: \", mse4, \"\\nRMSE: \", rmse4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see, the random forest algorithm even without tuning parameters is still producing a better MSE than the decision tree algorithm with tuning! We still have to account for overfitting, though, and tune the parameters here further. We may even get the benefit of an even more reduced MSE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  2798.856470447644 \n",
      "RMSE:  52.90421977921652\n"
     ]
    }
   ],
   "source": [
    "# generate new random forest instance\n",
    "rf2 = RandomForestRegressor(max_depth=10, min_samples_leaf=5)\n",
    "\n",
    "# train the model - we use ravel (converts to 1d array in np to avoid warnings)\n",
    "rf2.fit(train[features], np.ravel(train[['cnt']]))\n",
    "\n",
    "# make predictions on test\n",
    "predictions = rf2.predict(test[features])\n",
    "\n",
    "# calculate error and root\n",
    "mse5 = mean_squared_error(test[['cnt']], predictions)\n",
    "rmse5 = np.sqrt(mse5)\n",
    "\n",
    "# see the MSE and RMSE\n",
    "print(\"MSE: \", mse5, \"\\nRMSE: \", rmse5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that tuning the parameters won't do much more reducing for the MSE, but that's fine because we already found out that the random forest algorithm in general reduced it a lot from decision trees. To check for overfitting, we can check the MSE of a prediction on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  2115.131479513016 \n",
      "RMSE:  45.99055859100883\n"
     ]
    }
   ],
   "source": [
    "# make predictions on train\n",
    "predictions = rf2.predict(train[features])\n",
    "\n",
    "# calculate error and root\n",
    "mse6 = mean_squared_error(train[['cnt']], predictions)\n",
    "rmse6 = np.sqrt(mse6)\n",
    "\n",
    "# see the MSE and RMSE\n",
    "print(\"MSE: \", mse6, \"\\nRMSE: \", rmse6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, the training MSE is a little bit less than the test MSE, which may be some indication of overfitting. However, the training error rate is more or less always going to be less than the test error rate purely due to the nature of the model. \n",
    "\n",
    "Judging by the overall RMSE difference (again, a subjective judgement), we should be okay in terms of overfitting this time with this model.\n",
    "\n",
    "We can also test overfitting with any of the other previous models as well this way if we wish. It is the same process, so all we would have to do is copy the code over. We just did it for the last iteration and final random forest model here to avoid redundancy. The final model managed to produce an RMSE of just around 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Analysis / Next Steps\n",
    "Like always, there are a few more things about the project we can do that will be described below..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Features\n",
    "We calculated the \"time_label\" feature as an example of a way to make features 'better', but there are a few other ways to go about it too.\n",
    "\n",
    "One such example is making an index - combining things such as temperature, humidity, and wind speed. This has already been done of course, because it's useful! Temperature + humidity is called the Heat Index, and temperature + wind speed is called the Wind Chill.\n",
    "\n",
    "The formulas for Heat Index and Wind Chill look complicated, but they're really just plug and chug once you have them down. They can be found here:\n",
    "https://en.wikipedia.org/wiki/Heat_index and https://www.calculator.net/wind-chill-calculator.html.\n",
    "\n",
    "Our problem is, however, temperature is recorded in our dataset not as an absolute F or C, but as a relative number on a scale of 0 to 1. We have no way of knowing if 0 is actually 0 degrees or if 1 is 100 degrees, so these calculations may become a bit off. \n",
    "\n",
    "We'll use the alternative of just doing a basic weighting system to show how new features can be calculated from old ones. If we had the actual absolute temperatures, the process would be the same.\n",
    "\n",
    "Thinking of arbitrary weights, we'll go with something like 50% atemp (adjusted temp), 10% temp, 30% humidity, and 10% wind speed for our very greatly named \"Bike Feel Index\". \n",
    "\n",
    "Temperature will account for 60% of the index because that is what people pay the most attention to, afterall. Humidity gets some weight because sometimes it can affect your decision to rent a bike, but not most of the time - hence 30%. And finaly, wind speed gets 10% weight because it is also an environmental factor but the least worrysome for renters in our opinion. We create the feature below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>time_label</th>\n",
       "      <th>bike_feel_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.41095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \\\n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16   \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40   \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32   \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13   \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1   \n",
       "\n",
       "   time_label  bike_feel_index  \n",
       "0           4          0.41095  \n",
       "1           4          0.39835  \n",
       "2           4          0.39835  \n",
       "3           4          0.39295  \n",
       "4           4          0.39295  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# produce weighted column\n",
    "bike_rentals['bike_feel_index'] = (bike_rentals['temp'] * 0.1) + (bike_rentals['atemp'] * 0.5) + (bike_rentals['hum'] * 0.3) + (bike_rentals['windspeed'] * 0.1)\n",
    "            \n",
    "# see the df again\n",
    "bike_rentals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this as an example to redo our random forest model with the index: (We will re-import code in below to produce the train and test sets again with the new column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13903\n",
      "3476\n"
     ]
    }
   ],
   "source": [
    "# get the 80% index of df\n",
    "cutoff = int(bike_rentals.shape[0] * 0.8)\n",
    "\n",
    "# set 80% of rows to train using sampling\n",
    "# random state = 1 is set for documentation purposes - remove parameter in real life\n",
    "train = bike_rentals.sample(n=cutoff, random_state=1)\n",
    "\n",
    "# set the rest of the rows to test set\n",
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]\n",
    "\n",
    "#  confirm size of each\n",
    "print(train.shape[0])\n",
    "print(test.shape[0])\n",
    "\n",
    "# get list of columns\n",
    "features = list(bike_rentals.columns)\n",
    "\n",
    "# remove what we don't want\n",
    "features.remove(\"cnt\")\n",
    "features.remove(\"casual\")\n",
    "features.remove(\"registered\")\n",
    "features.remove(\"dteday\")\n",
    "features.remove(\"instant\")\n",
    "features.remove(\"holiday\")\n",
    "\n",
    "# remove columns our index replaced\n",
    "features.remove(\"temp\")\n",
    "features.remove(\"atemp\")\n",
    "features.remove(\"hum\")\n",
    "features.remove(\"windspeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  2688.147535345936 \n",
      "RMSE:  51.84734839262212\n"
     ]
    }
   ],
   "source": [
    "# generate new random forest instance\n",
    "rf3 = RandomForestRegressor(max_depth=15, min_samples_leaf=5)\n",
    "\n",
    "# train the model - we use ravel (converts to 1d array in np to avoid warnings)\n",
    "rf3.fit(train[features], np.ravel(train[['cnt']]))\n",
    "\n",
    "# make predictions on test\n",
    "predictions = rf3.predict(test[features])\n",
    "\n",
    "# calculate error and root\n",
    "mse7 = mean_squared_error(test[['cnt']], predictions)\n",
    "rmse7 = np.sqrt(mse7)\n",
    "\n",
    "# see the MSE and RMSE\n",
    "print(\"MSE: \", mse7, \"\\nRMSE: \", rmse7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it helped a tiny tiny bit, but not much. We can't really expect groundbreaking moves from a simple weighting, even though sometimes it will make a lot of sense and actually do so. This was just an example.\n",
    "\n",
    "If anything, we managed to eliminate the number of features we had by 3 and still got the same results, so at least this is good. It is always better to be simple, all other things being equal. If we had actual absolute temperatures, perhaps using the Heat Index and Wind Chill would have produced optimal results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Other Things\n",
    "If we wanted to, we could try and predict the number of casual or registered riders instead of total renters. The process for this will actually be almost exactly the same, so we'll save the redundancy. A quick example for predicting casual will be below just for show. It's the same code, with a few things adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  318.1132791301953 \n",
      "RMSE:  17.8357304064116\n"
     ]
    }
   ],
   "source": [
    "# retrain previous model\n",
    "rf3.fit(train[features], np.ravel(train[['casual']]))\n",
    "\n",
    "# make predictions on test\n",
    "predictions = rf3.predict(test[features])\n",
    "\n",
    "# calculate error and root\n",
    "mse8 = mean_squared_error(test[['casual']], predictions)\n",
    "rmse8 = np.sqrt(mse8)\n",
    "\n",
    "# see the MSE and RMSE\n",
    "print(\"MSE: \", mse8, \"\\nRMSE: \", rmse8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is a lot less, but this is because the average number of casual riders is also a lot less, so it is accounted for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.67621842453536\n"
     ]
    }
   ],
   "source": [
    "print(bike_rentals['casual'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "To sum everything up, in this project we used a few ML algorithms to build models that would predict the number of bike rentals in Washington DC. We determined that the random forest algorithm worked best for this dataset, and could get a prediction that wasn't *terrible*.\n",
    "\n",
    "This was also a basis to show the pros and cons of basic linear regression vs. neural network algorithms like decision trees and random forests. While linear regression is very quick and efficient, sometimes it wll underfit and may not be as accurate. On the other hand, trees and forests are much more complex and thus more accurate, but this also makes them prone to overfitting. \n",
    "\n",
    "We can probably get this prediction down to just a few dozen rentals at most if we did things like more complex features, incorporating another dataset, adjusted a few more parameters, etc. The point is, all the tools we have are right there to build a successful model. Nothing is out of reach at this point! However, we have to be sure to understand the fundamentals of the math. No one can just pick up these models and go to town (well, they *can*, but if something goes wrong, it'll probably be a nightmare)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
